{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from loader import Loader\n",
    "from AutoRec import *\n",
    "from datetime import datetime\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_user======\n",
      "3916\n",
      "n_item======\n",
      "34\n",
      "購買記錄_筆數\n",
      "4438\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../../../data/buy_count.csv')\n",
    "train, test = train_test_split(df, test_size=0.1, random_state=777)\n",
    "\n",
    "train_x = train.to_numpy().astype(np.int32)\n",
    "train_y = train['buy_count'].to_numpy().astype(np.float32)\n",
    "\n",
    "test_x = test.to_numpy().astype(np.int32)\n",
    "test_y = test['buy_count'].to_numpy().astype(np.float32)\n",
    "\n",
    "n_user = int(len(df[\"user_id\"].unique()))\n",
    "n_item = 34\n",
    "print('n_user======')\n",
    "print(n_user)\n",
    "print('n_item======')\n",
    "print(n_item)\n",
    "print(\"購買記錄_筆數\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyer-parameters\n",
    "lr = 1e-2  # Learning Rate\n",
    "k = 4\n",
    "batchsize = 256\n",
    "n_epochs = 500\n",
    "log_interval = 2\n",
    "default_vlaue = 1  # for test users and items without training observations\n",
    "log_dir = 'runs/AutoRec_' + 'k=' + str(k) + ',lr='+str(lr)+'batchsize='+str(batchsize) + \\\n",
    "    str(datetime.now()).replace(' ', '_')\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "train_loader = Loader(train_x, train_y, n_user, n_item,\n",
    "                      batchsize=batchsize, do_shuffle=False)\n",
    "test_loader = Loader(test_x, test_y, n_user, n_item,\n",
    "                     batchsize=batchsize, do_shuffle=False)\n",
    "# model\n",
    "model = AutoRec(n_user, n_item, k=k)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(epochs):\n",
    "    iter = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_train_error = 0\n",
    "        for i, (batch_x, batch_mask_x) in enumerate(train_loader):\n",
    "            iter += 1\n",
    "            batch_x = torch.from_numpy(batch_x.astype(np.float32))\n",
    "            batch_mask_x = torch.from_numpy(batch_mask_x.astype(np.float32))\n",
    "            pred = model(batch_x)\n",
    "            loss, rmse = model.loss(\n",
    "                decoder=pred, input=batch_x, optimizer=optimizer, mask_input=batch_mask_x)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_error += rmse\n",
    "            if iter % log_interval == 0:\n",
    "                fmt = \"Epoch[{}] Iteration[{}/{}] RMSE: {:.2f}\"\n",
    "                msg = fmt.format(epoch + 1, iter, len(\n",
    "                    train_loader), rmse)\n",
    "                print(msg)\n",
    "        epoch_train_error = epoch_train_error / len(train_loader)\n",
    "        print(\"Epoch[{}] training RMSE: {:.2f} \".format(\n",
    "            epoch+1, epoch_train_error))\n",
    "        writer.add_scalar(\"training/RMSE\", epoch_train_error, epoch)\n",
    "        # validation\n",
    "        for i, (batch_x, batch_mask_x) in enumerate(test_loader):\n",
    "            batch_x = torch.from_numpy(batch_x.astype(np.float32))\n",
    "            batch_mask_x = torch.from_numpy(batch_mask_x.astype(np.float32))\n",
    "            pred = model(batch_x)\n",
    "\n",
    "            untrained_user_list = list(test_x[(\n",
    "                np.isin(test_x[:, 0], train_x[:, 0]) == False), 0])\n",
    "            untrained_item_list = list(test_x[(\n",
    "                np.isin(test_x[:, 1], train_x[:, 1]) == False), 1])\n",
    "            for u_user in untrained_user_list:\n",
    "                for u_item in untrained_item_list:\n",
    "                    pred[u_user, u_item] = 1\n",
    "            vali_rmse = torch.sqrt((((pred - batch_x) * batch_mask_x).pow(2).sum()\n",
    "                                    ) / (batch_mask_x == 1).sum())\n",
    "            print(\"Epoch[{}] Validation RMSE: {:.2f} \".format(\n",
    "                epoch+1, vali_rmse))\n",
    "            writer.add_scalar(\"validation/RMSE\", vali_rmse, epoch)\n",
    "\n",
    "train_loop(epochs=n_epochs)\n",
    "torch.save(model.state_dict(), '../../models/AutoRec.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
